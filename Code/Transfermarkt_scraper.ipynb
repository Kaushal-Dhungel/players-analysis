{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6986c14",
   "metadata": {},
   "source": [
    "### 1. SCRAPE ALL CLUB LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_club_urls = {}\n",
    "\n",
    "# this link is for PL, I updated it manually for five different leagues\n",
    "url = \"https://www.transfermarkt.us/premier-league/startseite/wettbewerb/GB1\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,\"\n",
    "            \"image/avif,image/webp,image/apng,*/*;q=0.8,\"\n",
    "            \"application/signed-exchange;v=b3;q=0.7\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.google.com/\",\n",
    "    \"DNT\": \"1\", \n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "response = session.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "anchors = soup.find_all('a', href=re.compile(r'/.*?/startseite/verein/\\d+/saison_id/\\d+'))\n",
    "hrefs = list({a['href'] for a in anchors if a.has_attr('href')})\n",
    "\n",
    "# Again, I updated the league name manually, example :- pl, league1, bundesliga etc\n",
    "all_club_urls[\"pl\"] = hrefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"transfermarkt/all_clubs_tfmkt.json\", \"w\") as file:\n",
    "    json.dump(all_club_urls, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b77ce7",
   "metadata": {},
   "source": [
    "### 2. SCRAPE ALL PLAYERS LINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cdf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_players_link = {}\n",
    "\n",
    "def scrape_players(league,hrefs):\n",
    "    all_list = []\n",
    "    for href in hrefs:\n",
    "        url = f\"https://www.transfermarkt.us{href}\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                        \"Chrome/122.0.0.0 Safari/537.36\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,\"\n",
    "                    \"image/avif,image/webp,image/apng,*/*;q=0.8,\"\n",
    "                    \"application/signed-exchange;v=b3;q=0.7\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "            \"Referer\": \"https://www.google.com/\",\n",
    "            \"DNT\": \"1\",  # Do Not Track\n",
    "            \"Connection\": \"keep-alive\",\n",
    "            \"Upgrade-Insecure-Requests\": \"1\"\n",
    "        }\n",
    "\n",
    "        session = requests.Session()\n",
    "        response = session.get(url, headers=headers)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        anchors = soup.find_all('a', href=re.compile(r'/profil/spieler/'))\n",
    "        refs = list({a['href'] for a in anchors if a.has_attr('href')})\n",
    "        all_list += refs\n",
    "        \n",
    "        time.sleep(4)\n",
    "    league_players_link[league] = all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in all_club_urls.items():\n",
    "    scrape_players(key, all_club_urls[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9938bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfermarkt/all_players_link.json\", \"w\") as file:\n",
    "    json.dump(league_players_link, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c44d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "156757ad",
   "metadata": {},
   "source": [
    "### 3. SCRAPE ALL PLAYERS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbref_df = pd.read_csv(\"fbref_final.csv\")\n",
    "all_fbref_players = list(fbref_df [\"Name\"])\n",
    "\n",
    "player_unique_list = []\n",
    "error_players_list = []\n",
    "missed_players_list = []\n",
    "\n",
    "new_columns = [\n",
    "\"Name\",\n",
    "\"Age\",\n",
    "\"Playing Stats\",\n",
    "\"Market Value\"\n",
    "]\n",
    "all_transfermarkt_df = pd.DataFrame(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f839a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_players_stats_selenium(link_set):\n",
    "    global all_transfermarkt_df \n",
    "\n",
    "    for link in link_set:\n",
    "        player_name = link.split(\"/\")[1]\n",
    "        player_name = [i.capitalize() for i in player_name.split(\"-\")]\n",
    "        player_name = \" \".join(player_name)\n",
    "\n",
    "        if player_name in all_fbref_players:\n",
    "            if player_name in player_unique_list or player_name in missed_players_list:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                url = f\"https://www.transfermarkt.us{link}\"\n",
    "\n",
    "                options = Options()\n",
    "                options.add_argument(\"--headless=new\")\n",
    "                options.add_argument(\"--disable-gpu\")\n",
    "                options.add_argument(\"--window-size=1920,1080\")\n",
    "                options.add_argument(\"--no-sandbox\")\n",
    "                options.add_argument(\"--disable-dev-shm-usage\")\n",
    "                options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                                    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                                    \"Chrome/122.0.0.0 Safari/537.36\")\n",
    "\n",
    "                driver = webdriver.Chrome(options=options)\n",
    "                driver.get(url)\n",
    "                time.sleep(5)\n",
    "\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                # Extract Playing Stats\n",
    "                minutes = soup.find_all(class_=\"percentage-value\")\n",
    "                minutes = [span.text.strip() for span in minutes]\n",
    "                playing_stats = \",\".join(minutes)\n",
    "\n",
    "                # Extract Age\n",
    "                age_tag = soup.find(\"span\", class_=\"data-header__content\", itemprop=\"birthDate\")\n",
    "                age = age_tag.text.strip() if age_tag else None\n",
    "\n",
    "                # Extract Market Value\n",
    "                market_tag = soup.find(\"a\", class_=\"data-header__market-value-wrapper\")\n",
    "                market_val = market_tag.get_text(strip=True) if market_tag else None\n",
    "                match = re.search(r\"\\d+\\.\\d+\", market_val) if market_val else None\n",
    "                market_val = float(match.group()) if match else None\n",
    "\n",
    "                driver.quit()\n",
    "\n",
    "                new_row = {\n",
    "                    \"Name\": player_name,\n",
    "                    \"Age\": age,\n",
    "                    \"Playing Stats\": playing_stats,\n",
    "                    \"Market Value\": market_val\n",
    "                }\n",
    "                all_transfermarkt_df = pd.concat(\n",
    "                    [all_transfermarkt_df, pd.DataFrame([new_row])],\n",
    "                    ignore_index=True\n",
    "                )\n",
    "\n",
    "                player_unique_list.append(player_name)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print (\"Exception occured for player\", player_name, e)\n",
    "                error_players_list.append(player_name)\n",
    "\n",
    "        else:\n",
    "            missed_players_list.append(player_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f559f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfermarkt/all_players_link.json\", \"r\") as f:\n",
    "    league_players_link = json.load(f)\n",
    "\n",
    "\n",
    "for key,val in league_players_link.items():\n",
    "    scrape_players_stats_selenium(league_players_link[key])\n",
    "    all_transfermarkt_df.to_csv(f\"transfermarkt/{key}_players_tfmkt.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae1ab8",
   "metadata": {},
   "source": [
    "### 4. CLEAN AND MERGE ALL PLAYERS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [\n",
    "\"Name\",\n",
    "\"Age\",\n",
    "\"Playing Stats\",\n",
    "\"Market Value\"\n",
    "]\n",
    "all_transfermarkt_df = pd.DataFrame(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc511ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global all_transfermarkt_df\n",
    "for file in os.listdir(\"transfermarkt\"):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    league_name = file.replace(\".csv\",\"\").split(\"_\")[0]\n",
    "    df = pd.read_csv(\"transfermarkt/\" + file)\n",
    "    all_transfermarkt_df = pd.concat([all_transfermarkt_df,df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transfermarkt_df[\"Age\"] = all_transfermarkt_df[\"Age\"].apply(lambda x: x.split(\"(\")[1][:2])\n",
    "all_transfermarkt_df=all_transfermarkt_df.drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "all_transfermarkt_df[['Starting Eleven', 'Minutes', 'Goal Involvement']] = all_transfermarkt_df['Playing Stats'].str.split(',', expand=True)\n",
    "all_transfermarkt_df = all_transfermarkt_df.drop(columns=[\"Playing Stats\"], axis=1)\n",
    "all_transfermarkt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3922dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transfermarkt_df.to_csv(\"transfermarkt_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
